
# Lab 2 : CNN, Faster R-CNN et Vision Transformer sur MNIST

##  Université Abdelmalek Essaâdi – FST Tanger
**Master : MSITBD – Deep Learning**  
Encadré par : Pr. EL AACHIK LOTFI  

##  Objectif
Implémenter et comparer plusieurs architectures de Deep Learning (CNN, VGG16, Faster R-CNN et Vision Transformer) sur le jeu de données MNIST en utilisant PyTorch et Google Colab.

---

##  Dataset
MNIST (chiffres manuscrits : 0 → 9)  
- 60 000 images d’entraînement  
- 10 000 images de test  

---

##  Modèles utilisés

| Modèle | Accuracy | F1-Score |
|------|--------|--------|
| CNN | 0.9864 | 0.9864 |
| VGG16 | 0.9054 | 0.9059 |
| Vision Transformer | **0.9943** | **0.9943** |

 Meilleur modèle : **Vision Transformer (ViT)**

---

##  Technologies utilisées

- Python
- PyTorch
- torchvision
- timm (pour ViT)
- Google Colab
- GitHub

---

##  Comment exécuter le projet

1. Ouvrir le notebook dans Google Colab
2. Activer le GPU
3. Exécuter les cellules une par une

---

##  Conclusion

Le Vision Transformer obtient la meilleure performance sur MNIST.  
Le CNN offre un excellent rapport simplicité / efficacité.

---

##  Réalisé par

** HALA RAMI **  

